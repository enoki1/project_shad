{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3b08864a-47dd-412e-92b5-e9333e229cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import typing as ty\n",
    "from torch import Tensor\n",
    "from catboost import CatBoostClassifier\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import trange\n",
    "from IPython.display import clear_output\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import QuantileTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a8018750-d1dd-468e-af4d-7d0afc6d7ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def DataLoadAndScale(dataset_folder, normalizer='standard', regression=False, seed=777, noise=1e-3):\n",
    "    X_train = np.load(f'data_tabular/{dataset_folder}/N_train.npy')\n",
    "    y_train = np.load(f'data_tabular/{dataset_folder}/y_train.npy')\n",
    "    X_test = np.load(f'data_tabular/{dataset_folder}/N_test.npy')\n",
    "    y_test = np.load(f'data_tabular/{dataset_folder}/y_test.npy')\n",
    "    X_val = np.load(f'data_tabular/{dataset_folder}/N_val.npy')\n",
    "    y_val = np.load(f'data_tabular/{dataset_folder}/y_val.npy')\n",
    "\n",
    "    m, s = y_train.mean(), y_train.std()\n",
    "    if regression == True:\n",
    "        y_train = (y_train - m) / s\n",
    "        y_val = (y_val - m) / s\n",
    "        y_test = (y_test - m) / s\n",
    "\n",
    "    data_cb = {\n",
    "        'X_train' : X_train,\n",
    "        'X_val' : X_val,\n",
    "        'X_test' : X_test,\n",
    "        'y_train' : y_train,\n",
    "        'y_val' : y_val,\n",
    "        'y_test' : y_test,\n",
    "        'mean' : m,\n",
    "        'std' : s\n",
    "    }\n",
    "    imputer = SimpleImputer(strategy='mean')\n",
    "    X_train = imputer.fit_transform(X_train)\n",
    "    X_val = imputer.transform(X_val)\n",
    "    X_test = imputer.transform(X_test)\n",
    "    \n",
    "    data_model = {}\n",
    "    if normalizer == 'standard':\n",
    "        scaler = StandardScaler()\n",
    "        data_model['X_train'] = torch.from_numpy(scaler.fit_transform(X_train))\n",
    "        data_model['X_test'] = torch.from_numpy(scaler.transform(X_test))\n",
    "        data_model['X_val'] = torch.from_numpy(scaler.transform(X_val))\n",
    "    else:\n",
    "        quantile_transformer_params = {\n",
    "            'output_distribution' : 'normal',\n",
    "            'n_quantiles' : max(min(X_train.shape[0] // 30, 100), 10), # можно поменять здесь\n",
    "            'subsample' : int(1e9)\n",
    "        }\n",
    "        stds = np.std(X_train, axis=0, keepdims=True)\n",
    "        noise_std = noise / np.maximum(stds, noise)  # type: ignore[code]\n",
    "        X_train_new = X_train + noise_std * np.random.default_rng(seed).standard_normal(  # type: ignore[code]\n",
    "                X_train.shape\n",
    "        ).astype('float32')\n",
    "        transformer = QuantileTransformer(**quantile_transformer_params)\n",
    "        data_model['X_train'] = torch.from_numpy(transformer.fit_transform(X_train_new))\n",
    "        data_model['X_test'] = torch.from_numpy(transformer.transform(X_test))\n",
    "        data_model['X_val'] = torch.from_numpy(transformer.transform(X_val))\n",
    "\n",
    "    data_model['y_train'] = torch.from_numpy(y_train)\n",
    "    data_model['y_test'] = torch.from_numpy(y_test)\n",
    "    data_model['y_val']= torch.from_numpy(y_val)\n",
    "    data_model['mean'] = m\n",
    "    data_model['std'] = s\n",
    "    \n",
    "    return data_model, data_cb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ffd022ca-f9a8-4ace-8b30-eb866f8dbc84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_num_params(model):\n",
    "    sum_params = 0\n",
    "    for param in model.named_parameters():\n",
    "        num_params = np.prod(param[1].shape)\n",
    "        print('{: <19} ~  {: <7} params'.format(param[0], num_params))\n",
    "        sum_params += num_params\n",
    "    print(f'\\nIn total: {sum_params} params')\n",
    "    return sum_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6b304ec5-b177-4748-9c6b-addcb115fc68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model_and_optimizer(model_class, model_params, optimizer_params, device=device):\n",
    "    model = model_class(**model_params)\n",
    "    model = model.to(device)\n",
    "    \n",
    "    optimizer = torch.optim.AdamW(model.parameters(), **optimizer_params)\n",
    "    return model, optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "adc1b100-5fb6-4a01-8343-d51a625b0686",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_results(model, criterion, X_train, y_train, X_val, y_val, X_test, y_test, metric, regression=False):\n",
    "#     model.eval()\n",
    "#     X_train_dev = X_train.to(device)\n",
    "#     X_val_dev = X_val.to(device)\n",
    "#     X_test_dev = X_test.to(device)\n",
    "#     y_val_dev = y_val.to(device)\n",
    "#     y_test_dev = y_test.to(device)\n",
    "#     with torch.no_grad():\n",
    "#         preds_val = model(X_val_dev, None)\n",
    "#         preds_test = model(X_test_dev, None)\n",
    "#         preds_train = model(X_train_dev, None)\n",
    "#         val_loss = criterion(preds_val, y_val_dev)\n",
    "#         test_loss = criterion(preds_test, y_test_dev)\n",
    "        \n",
    "#         if regression == False:\n",
    "#             preds_train = torch.argmax(torch.softmax(preds_train, dim=-1), dim=-1)\n",
    "#             preds_val = torch.argmax(torch.softmax(preds_val, dim=-1), dim=-1)\n",
    "#             preds_test = torch.argmax(torch.softmax(preds_test, dim=-1), dim=-1)\n",
    "        \n",
    "#         preds_train = preds_train.detach().cpu().numpy()\n",
    "#         preds_val = preds_val.detach().cpu().numpy()\n",
    "#         preds_test = preds_test.detach().cpu().numpy()\n",
    "\n",
    "#         return metric(y_val, preds_val), val_loss, metric(y_test, preds_test), test_loss, metric(y_train, preds_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "842b6e70-f4a7-4435-a5c5-e4b440bf41f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def epoch_eval(model, data, labels, batch_size, criterion, metric, regression=False):\n",
    "    num_batches = (data.shape[0] + batch_size - 1) // batch_size\n",
    "    model.eval()\n",
    "    average_loss = 0.0\n",
    "    average_metric = 0.0\n",
    "    with torch.no_grad():\n",
    "        for batch_index in range(num_batches):\n",
    "            batch_X = data[batch_index * batch_size : min((batch_index + 1) * batch_size, data.shape[0])].to(device)\n",
    "            batch_y = labels[batch_index * batch_size : min((batch_index + 1) * batch_size, data.shape[0])].to(device)\n",
    "            preds = model(batch_X, None)\n",
    "            loss = criterion(preds, batch_y)\n",
    "            batch_y = batch_y.detach().cpu().numpy()\n",
    "            \n",
    "            if batch_index < num_batches - 1:\n",
    "                average_loss += loss.item()\n",
    "                \n",
    "            if regression == False:\n",
    "                preds = torch.argmax(torch.softmax(preds, dim=-1), dim=-1).detach().cpu().numpy()\n",
    "                if batch_index < num_batches - 1:\n",
    "                    average_metric += metric(batch_y, preds)\n",
    "            else:\n",
    "                preds = preds.detach().cpu().numpy()\n",
    "                if batch_index < num_batches - 1:\n",
    "                    average_metric += metric(batch_y, preds)**(0.5)\n",
    "        return average_loss / (num_batches - 1), average_metric / (num_batches - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "90b8dc6d-3a08-4808-9b5e-50e48190d7be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def epoch_eval_labels(model, data, batch_size, regression=False):\n",
    "    num_batches = (data.shape[0] + batch_size - 1) // batch_size\n",
    "    model.eval()\n",
    "    labels = []\n",
    "    with torch.no_grad():\n",
    "        for batch_index in range(num_batches):\n",
    "            batch_X = data[batch_index * batch_size : min((batch_index + 1) * batch_size, data.shape[0])].to(device)\n",
    "            preds = model(batch_X, None)\n",
    "  \n",
    "            if regression == False:\n",
    "                preds = torch.argmax(torch.softmax(preds, dim=-1), dim=-1).detach().cpu().numpy()\n",
    "            else:\n",
    "                preds = preds.detach().cpu().numpy()\n",
    "            labels.extend(preds)\n",
    "        labels = torch.tensor(labels, dtype=torch.int32) if regression==False else torch.tensor(labels, dtype=torch.float32)\n",
    "        return labels    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "46147ebc-997a-4331-81da-223d0e701fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_results(model, criterion, X_train, y_train, X_val, y_val, X_test, y_test, metric, eval_batch_size, regression=False):\n",
    "    train_loss, train_metric = epoch_eval(model, X_train, y_train, eval_batch_size, criterion, metric, regression)\n",
    "    val_loss, val_metric = epoch_eval(model, X_val, y_val, eval_batch_size, criterion, metric, regression)\n",
    "    test_loss, test_metric = epoch_eval(model, X_test, y_test, eval_batch_size, criterion, metric, regression)\n",
    "    return val_metric, val_loss, test_metric, test_loss, train_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c3a0131-f714-4726-95b1-84b1766797f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(model, optimizer, X_train, y_train, X_val, y_val, X_test, y_test, mean, std,\n",
    "               criterion, num_epochs, batch_size, eval_batch_size, patience, metric, file_to_load, model_num=None, regression=False):\n",
    "    epoch_val_accuracy = []\n",
    "    epoch_test_accuracy = []\n",
    "    epoch_train_accuracy = []\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    test_losses = []\n",
    "    num_batches = (X_train.shape[0] + batch_size - 1) // batch_size\n",
    "    max_val_accuracy = -10 if regression == False else 1e9\n",
    "    for epoch_index in trange(num_epochs):\n",
    "        model.train(True)\n",
    "        epoch_average_loss = 0.0\n",
    "        for batch_index in range(num_batches):\n",
    "            batch_X = X_train[batch_index * batch_size : min((batch_index + 1) * batch_size, X_train.shape[0])].to(device)\n",
    "            batch_y = y_train[batch_index * batch_size : min((batch_index + 1) * batch_size, X_train.shape[0])].to(device)\n",
    "            preds = model(batch_X, None)\n",
    "    \n",
    "            loss = criterion(preds, batch_y)\n",
    "            if batch_index < num_batches - 1:\n",
    "                epoch_average_loss += loss.item()\n",
    "                \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "        train_losses.append(epoch_average_loss / (num_batches - 1))\n",
    "        \n",
    "        val_accuracy, val_loss, test_accuracy, test_loss, train_accuracy = get_results(model,criterion, X_train, y_train,\n",
    "                                                                                       X_val, y_val, X_test, y_test, metric, eval_batch_size,\n",
    "                                                                                       regression=regression)\n",
    "        \n",
    "        epoch_val_accuracy.append(val_accuracy)\n",
    "        if val_accuracy > max_val_accuracy and regression == False:\n",
    "            torch.save(model.state_dict(), f'{file_to_load}')\n",
    "            max_val_accuracy = val_accuracy\n",
    "        elif val_accuracy < max_val_accuracy and regression == True:\n",
    "            torch.save(model.state_dict(), f'{file_to_load}')\n",
    "            max_val_accuracy = val_accuracy\n",
    "            \n",
    "        epoch_test_accuracy.append(test_accuracy)\n",
    "        epoch_train_accuracy.append(train_accuracy)\n",
    "        val_losses.append(val_loss)\n",
    "        test_losses.append(test_loss)\n",
    "        \n",
    "                \n",
    "        clear_output(True)\n",
    "        fig, ax = plt.subplots(1, 2, figsize=(20, 10))\n",
    "        fig.suptitle(f'#{epoch_index}/{num_epochs}:')\n",
    "        plt.subplot(121)\n",
    "        plt.title('loss' if model_num == None else f\"loss_model{model_num}\")\n",
    "        plt.plot(train_losses, 'r.-', label='train')\n",
    "        plt.plot(val_losses, 'g.-', label='val')\n",
    "        plt.plot(test_losses, 'y.-', label='test')\n",
    "        plt.legend()\n",
    "        plt.grid()\n",
    "        plt.subplot(122)\n",
    "        plt.title('accuracy' if model_num == None else f\"accuracy_model{model_num}\")\n",
    "        plt.plot(epoch_train_accuracy, 'r.-', label='train')\n",
    "        plt.plot(epoch_val_accuracy, 'g.-', label='val')\n",
    "        plt.plot(epoch_test_accuracy, 'y.-', label='test')\n",
    "        plt.legend()\n",
    "        plt.grid()\n",
    "        plt.show()        \n",
    "    return epoch_test_accuracy, val_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "03a0f0f0-f402-463e-98a3-95a01c87975f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def LearnNModels(N, model_name, model_params, optimizer_params, data, train_params, metric, file_to_load, regression=False):\n",
    "    models = []\n",
    "    y_train_labels = []\n",
    "    y_val_labels = []\n",
    "    y_test_labels = []\n",
    "    accuracy = []\n",
    "    for i in range(N):\n",
    "        model, opt = create_model_and_optimizer(model_name, model_params, optimizer_params)\n",
    "        epoch_test_accuracy, val_losses = train_loop(model, opt, **data, **train_params, metric=metric,\n",
    "                                                     model_num = i + 1, file_to_load=file_to_load, regression=regression)\n",
    "        model.load_state_dict(torch.load(f'{file_to_load}'))\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            train_labels = epoch_eval_labels(model, data['X_train'], train_params['eval_batch_size'], regression)\n",
    "            val_labels = epoch_eval_labels(model, data['X_val'], train_params['eval_batch_size'], regression)\n",
    "            test_labels = epoch_eval_labels(model, data['X_test'], train_params['eval_batch_size'], regression)\n",
    "                \n",
    "            y_train_labels.append(train_labels)\n",
    "            y_val_labels.append(val_labels)\n",
    "            y_test_labels.append(test_labels)\n",
    "            acc = metric(data['y_test'], test_labels)\n",
    "\n",
    "            accuracy.append(acc)\n",
    "        model = model.cpu()    \n",
    "        models.append(model)\n",
    "    return {'train_labels' : y_train_labels,\n",
    "            'val_labels' : y_val_labels,\n",
    "            'test_labels' : y_test_labels,\n",
    "            'accuracy' : accuracy,\n",
    "            'models' : models} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a0f4108-c0de-4c44-a9ae-2c6ee9b3a2c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CatBoostNLearning(teacher_training, cb_type, catboost_params, data_cb, metric, N=5, ensemble_size=5, regression=False, ensemble_N=3):\n",
    "    accuracy = {}\n",
    "    cb = cb_type(**catboost_params)\n",
    "    cb.fit(data_cb['X_train'], data_cb['y_train'], eval_set=(data_cb['X_val'], data_cb['y_val']))\n",
    "    preds = cb.predict(data_cb['X_test'])\n",
    "    accuracy['original'] = metric(data_cb['y_test'], preds)\n",
    "    \n",
    "    for i in trange(len(teacher_training['models'][:N])):\n",
    "        cb = cb_type(**catboost_params)\n",
    "        train_teacher_labels = teacher_training['train_labels'][i]\n",
    "        val_teacher_labels = teacher_training['val_labels'][i]\n",
    "        test_teacher_labels = teacher_training['test_labels'][i]\n",
    "        cb.fit(data_cb['X_train'], train_teacher_labels.numpy(), eval_set=(data_cb['X_val'], val_teacher_labels.numpy()))\n",
    "        predicts = cb.predict(data_cb['X_test'])\n",
    "        accuracy[f'distill_{i + 1}'] = metric(data_cb['y_test'], predicts)\n",
    "    \n",
    "    agg_func = torch.mode if regression == False else torch.mean\n",
    "    train_labels = []\n",
    "    val_labels = []\n",
    "    for i in range(ensemble_N):\n",
    "        train_labels.append(agg_func(torch.stack(teacher_training['train_labels'][i * ensemble_size:(i+1)*ensemble_size], dim=-1), dim=-1))\n",
    "    #train_labels2 = agg_func(torch.stack(teacher_training['train_labels'][ensemble_size:2*ensemble_size], dim=-1), dim=-1)\n",
    "    #train_labels3 = agg_func(torch.stack(teacher_training['train_labels'][2*ensemble_size:3*ensemble_size], dim=-1), dim=-1)\n",
    "        val_labels.append(agg_func(torch.stack(teacher_training['val_labels'][i*(ensemble_size):(i+1)*ensemble_size], dim=-1), dim=-1))\n",
    "    #val_labels1 = agg_func(torch.stack(teacher_training['val_labels'][:ensemble_size], dim=-1), dim=-1)\n",
    "    #val_labels2 = agg_func(torch.stack(teacher_training['val_labels'][ensemble_size:2*ensemble_size], dim=-1), dim=-1)\n",
    "    #val_labels3 = agg_func(torch.stack(teacher_training['val_labels'][2*ensemble_size:3*ensemble_size], dim=-1), dim=-1)\n",
    "\n",
    "    if regression == False:\n",
    "        for i in range(ensemble_N):\n",
    "            train_labels[i] = train_labels[i].values\n",
    "            val_labels[i] = val_labels[i].values\n",
    "\n",
    "    #train_labels = [train_labels1, train_labels2, train_labels3]\n",
    "    #val_labels = [val_labels1, val_labels2, val_labels3]\n",
    "    accuracy_ensemble = []\n",
    "\n",
    "    for i in range(ensemble_N):\n",
    "        cb = cb_type(**catboost_params)\n",
    "        cb.fit(data_cb['X_train'], train_labels[i].numpy(), eval_set=(data_cb['X_val'], val_labels[i].numpy()))\n",
    "        preds = cb.predict(data_cb['X_test'])\n",
    "        accuracy_ensemble.append(metric(data_cb['y_test'], preds))\n",
    "\n",
    "    # cb = cb_type(**catboost_params)\n",
    "    # cb.fit(data_cb['X_train'], train_labels2.numpy(), eval_set=(data_cb['X_val'], val_labels2.numpy()))\n",
    "    # preds = cb.predict(data_cb['X_test'])\n",
    "    # accuracy_ensemble.append(metric(data_cb['y_test'], preds))\n",
    "\n",
    "    # cb = cb_type(**catboost_params)\n",
    "    # cb.fit(data_cb['X_train'], train_labels3.numpy(), eval_set=(data_cb['X_val'], val_labels3.numpy()))\n",
    "    # preds = cb.predict(data_cb['X_test'])\n",
    "    # accuracy_ensemble.append(metric(data_cb['y_test'], preds))\n",
    "    return {'accuracy' : accuracy, 'accuracy_ensemble' : accuracy_ensemble}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "fb5c69ad-8a87-4283-8f46-d0215349b2e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def PrintResults(results_models_learning, results_cb_learning, regression=False, std = None):\n",
    "    for i in range(len(results_cb_learning['accuracy']) - 1):\n",
    "        model_metric = results_models_learning['accuracy'][i]\n",
    "        cb_original_metric = results_cb_learning['accuracy']['original']\n",
    "        cb_metric = results_cb_learning['accuracy'][f'distill_{i + 1}']\n",
    "        if regression == True:\n",
    "            model_metric = model_metric**(0.5) * std\n",
    "            cb_original_metric = cb_original_metric**(0.5) * std\n",
    "            cb_metric = cb_metric**(0.5) * std\n",
    "        print(f'model_{i}_metric : {model_metric}')\n",
    "        print(f'distill_{i} : {cb_original_metric} ---------> {cb_metric}')\n",
    "    average = 0.0\n",
    "    for i in range(len(results_cb_learning['accuracy_ensemble'])):\n",
    "        a = results_cb_learning['accuracy_ensemble'][i]\n",
    "        if regression == True:\n",
    "            a = a**(0.5) * std\n",
    "        average += a \n",
    "    print('averaged ensembles accuracy : ', average / len(results_cb_learning['accuracy_ensemble'])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7bc2fce-aa5e-4b15-a068-266e7a49f7d5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
